# -*- coding: utf-8 -*-
"""Youtube-Summarizer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cnWm1r4CPqXiSiGyuaK9zKTgh1lfXGpy
"""

!pip install -qU \
    langchain==0.0.292 \
    openai==0.28.0 \
    datasets==2.10.1 \
    pinecone-client==2.2.4 \
    tiktoken==0.5.1

!pip install deeplake

!pip install -q yt_dlp
!pip install -q git+https://github.com/openai/whisper.git

import os
os.environ['OPENAI_API_KEY'] = ''
os.environ["ACTIVELOOP_TOKEN"] = ""

import yt_dlp

def download_from_youtube(url):
  filename = 'video.mp4'
  ydl_opts = {
      'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',
      'outtmpl': filename,
      'quiet': True,
  }

  with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    result = ydl.extract_info(url, download=True)

url = "https://www.youtube.com/watch?v=N7RU6W4hAMI"
download_from_youtube(url)

import whisper
model = whisper.load_model('base')
result = model.transcribe('video.mp4')
print(result['text'])

with open ('text.txt', 'w') as file:
    file.write(result['text'])

from langchain import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain import OpenAI, LLMChain
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model='gpt-4', temperature=0)

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=0, separators=[" ", ",", "\n"]
)

from langchain.docstore.document import Document

with open('text.txt') as f:
    text = f.read()

texts = text_splitter.split_text(text)
docs = [Document(page_content=t) for t in texts[:4]]

from langchain.chains.summarize import load_summarize_chain
import textwrap

chain = load_summarize_chain(llm, chain_type="map_reduce")

output_summary = chain.run(docs)
wrapped_text = textwrap.fill(output_summary, width=100)
print(wrapped_text)





prompt_template = """Write a concise bullet point summary of the following:


{text}


CONSCISE SUMMARY IN BULLET POINTS:"""

BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template,
                        input_variables=["text"])

chain = load_summarize_chain(llm,
                             chain_type="stuff",
                             prompt=BULLET_POINT_PROMPT)

output_summary = chain.run(docs)

wrapped_text = textwrap.fill(output_summary,
                             width=1000,
                             break_long_words=False,
                             replace_whitespace=False)
print(wrapped_text)

chain = load_summarize_chain(llm, chain_type="refine")

output_summary = chain.run(docs)
wrapped_text = textwrap.fill(output_summary, width=100)
print(wrapped_text)

from langchain.vectorstores import DeepLake
from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')

dataset_path = f"hub://ihamzakhan89/langchain_course_fewshot_selector"
db = DeepLake(dataset_path=dataset_path)

db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)
db.add_documents(docs)

retriever = db.as_retriever()
retriever.search_kwargs['distance_metric'] = 'cos'
retriever.search_kwargs['k'] = 4

from langchain.prompts import PromptTemplate
prompt_template = """Use the following pieces of transcripts from a video to answer the question in bullet points and summarized. If you don't know the answer, just say that you don't know, don't try to make up an answer.

{context}

Question: {question}
Summarized answer in bullter points:"""
PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

from langchain.chains import RetrievalQA

chain_type_kwargs = {"prompt": PROMPT}
qa = RetrievalQA.from_chain_type(llm=llm,
                                 chain_type="stuff",
                                 retriever=retriever,
                                 chain_type_kwargs=chain_type_kwargs)

print( qa.run("Explain lifecyle of Data Science project according to the video.") )

